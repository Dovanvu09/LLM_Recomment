{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from openai import OpenAI\n",
    "from key import OPENAI_API_KEY\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to find most similar users\n",
    "def get_similar_users(user_id, matrix, m):\n",
    "    if user_id not in matrix.index:\n",
    "        return []\n",
    "    sim_users = matrix.loc[user_id].sort_values(ascending=False).iloc[1:m+1].index.tolist()\n",
    "    return sim_users\n",
    "\n",
    "def user_filtering_recommendations(dataframe, target_user_id, m, ns):\n",
    "    \"\"\"\n",
    "    Generate movie recommendations for a target user based on user-filtering.\n",
    "\n",
    "    :param dataframe: A pandas DataFrame containing columns 'user_id', 'movie_id', 'rating', 'movie title'.\n",
    "    :param target_user_id: The user ID for whom recommendations are to be generated.\n",
    "    :param m: The number of similar users to consider.\n",
    "    :param ns: The number of candidate items to recommend.\n",
    "    :return: A list of candidate movie titles.\n",
    "    \"\"\"\n",
    "    # Create a pivot table\n",
    "    user_movie_matrix = dataframe.pivot_table(index='user_id', columns='movie_id', values='avg_rating', fill_value=0)\n",
    "    # Convert to sparse matrix\n",
    "    sparse_matrix = csr_matrix(user_movie_matrix)\n",
    "    # Compute Cosine Similarity\n",
    "    cosine_sim = cosine_similarity(sparse_matrix)\n",
    "    # Convert to DataFrame\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim, index=user_movie_matrix.index, columns=user_movie_matrix.index)\n",
    "    # Find similar users\n",
    "    similar_users = get_similar_users(target_user_id, cosine_sim_df, m)\n",
    "    # Get candidate movie IDs\n",
    "    candidate_ids = dataframe[dataframe['user_id'].isin(similar_users)]['movie_id'].value_counts().head(ns).index\n",
    "    # Map IDs to Titles\n",
    "    candidate_titles = dataframe[dataframe['movie_id'].isin(candidate_ids)]['movie_title'].unique().tolist()\n",
    "    return candidate_titles\n",
    "\n",
    "# get recommendations from OpenAI\n",
    "def rec_from_openai(df, m, n, ns, user_id, temp_1, temp_2, client, random_seed=42):\n",
    "    \"\"\"\n",
    "    Generate movie recommendations for a target user based on user-filtering.\n",
    "    Input:\n",
    "        df: dataframe\n",
    "        m: number of similar users to consider\n",
    "        n: number of movies to select from total watched movies of this user\n",
    "        ns: number of candidate items to recommend\n",
    "        user_id: target user id\n",
    "        temp_1: OpenAI prompt template for step 1\n",
    "        temp_2: OpenAI prompt template for step 2\n",
    "    Output:\n",
    "        recommendations: a list of recommended movie titles\n",
    "        hit_rate: hit rate of recommendations in watched movies\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(random_seed)   \n",
    "\n",
    "    watched_movies = df[df['user_id'] == user_id]['movie_title'].unique().tolist()\n",
    "    selected_watched_movies = np.random.choice(watched_movies, min(len(watched_movies), n), replace=False).tolist()\n",
    "    # combine movie name and genre\n",
    "    selected_watched_movies_genres = set(df[df['movie_title'].isin(selected_watched_movies)]['genres'].unique().tolist())\n",
    "    candidate_movies = user_filtering_recommendations(df, target_user_id=user_id, m=m, ns=ns)\n",
    "    \n",
    "    Input_1 = temp_1.format(candidate_movies, selected_watched_movies, selected_watched_movies_genres)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages= [{ 'role':'user','content' : Input_1}],\n",
    "        # temperature=0,\n",
    "        # max_tokens=512,\n",
    "        # top_p=1,\n",
    "        # frequency_penalty=0,\n",
    "        # presence_penalty=0,\n",
    "        )\n",
    "    prediction_1 = response.choices[0].message.content\n",
    "\n",
    "    Input_2 = temp_2.format(candidate_movies, selected_watched_movies, selected_watched_movies_genres, prediction_1)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages= [{ 'role':'user','content' : Input_2}],\n",
    "        # temperature=0,\n",
    "        # max_tokens=512,\n",
    "        # top_p=1,\n",
    "        # frequency_penalty=0,\n",
    "        # presence_penalty=0,\n",
    "        )\n",
    "    prediction_2 = response.choices[0].message.content\n",
    "\n",
    "    # print(Input_1)\n",
    "    # print(prediction_1)\n",
    "    # print(Input_2)\n",
    "    # print(prediction_2)\n",
    "\n",
    "    recommendations = []\n",
    "    for movie in prediction_2.split('\\n'):\n",
    "        split_movie = movie.split('.')\n",
    "        if len(split_movie) > 1:\n",
    "            recommendations.append(split_movie[1].strip())\n",
    "    # hit rate of recommendations in watched movies\n",
    "    if len(recommendations) == 0:\n",
    "        hit_rate = 0\n",
    "    else:\n",
    "        hit_rate = len(set(recommendations).intersection(set(watched_movies))) / len(recommendations)\n",
    "\n",
    "    return recommendations, hit_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Toy Story (1995)', 'Jurassic Park (1993)', 'Nightmare Before Christmas, The (1993)', 'Terminator 2: Judgment Day (1991)', 'Silence of the Lambs, The (1991)', 'Fargo (1996)', 'Independence Day (ID4) (1996)', 'Raiders of the Lost Ark (1981)', 'Star Trek: First Contact (1996)', 'Jaws (1975)']\n",
      "1.0\n",
      "==================================================\n",
      "['A']\n",
      "0.0\n",
      "==================================================\n",
      "['Contact (1997)', 'Full Monty, The (1997)', 'Starship Troopers (1997)', 'Good Will Hunting (1997)', 'English Patient, The (1996)', 'Scream (1996)', 'Air Force One (1997)', \"Devil's Advocate, The (1997)\", 'Rainmaker, The (1997)', 'Titanic (1997)']\n",
      "0.6\n",
      "==================================================\n",
      "[\"Devil's Own, The (1997)\", 'Contact (1997)', 'Event Horizon (1997)', 'Starship Troopers (1997)', 'English Patient, The (1996)', 'Scream (1996)', 'Air Force One (1997)', 'In & Out (1997)', 'L', \"Devil's Advocate, The (1997)\"]\n",
      "0.6\n",
      "==================================================\n",
      "[]\n",
      "0\n",
      "==================================================\n",
      "[]\n",
      "0\n",
      "==================================================\n",
      "['Pulp Fiction (1994)', 'Forrest Gump (1994)', 'Lion King, The (1994)', 'Maverick (1994)', 'Fugitive, The (1993)', 'Blade Runner (1982)', 'Wizard of Oz, The (1939)', 'Citizen Kane (1941)', 'Sound of Music, The (1965)', 'Monty Python and the Holy Grail (1974)']\n",
      "1.0\n",
      "==================================================\n",
      "['']\n",
      "0.0\n",
      "==================================================\n",
      "['Toy Story (1995)', 'Star Wars (1977)', 'Return of the Jedi (1983)', 'Kolya (1996)', 'Contact (1997)', 'Full Monty, The (1997)', 'Heat (1995)', 'Leaving Las Vegas (1995)', 'English Patient, The (1996)', 'Liar Liar (1997)']\n",
      "0.5\n",
      "==================================================\n",
      "['Silence of the Lambs, The (1991)', 'Fargo (1996)', 'Lone Star (1996)', 'Wizard of Oz, The (1939)', '2001: A Space Odyssey (1968)', 'Monty Python and the Holy Grail (1974)', 'Raiders of the Lost Ark (1981)', 'GoodFellas (1990)', 'Psycho (1960)', 'Sting, The (1973)']\n",
      "1.0\n",
      "==================================================\n",
      "[]\n",
      "0\n",
      "==================================================\n",
      "['Apollo 13 (1995)', 'Star Wars (1977)', 'Forrest Gump (1994)', 'Lion King, The (1994)', 'Jurassic Park (1993)', 'Dances with Wolves (1990)', 'Silence of the Lambs, The (1991)', 'Independence Day (ID4) (1996)', 'Empire Strikes Back, The (1980)', 'Princess Bride, The (1987)']\n",
      "0.8\n",
      "==================================================\n",
      "['Get Shorty (1995)', 'Jurassic Park (1993)', 'Blade Runner (1982)', 'Dances with Wolves (1990)', 'Silence of the Lambs, The (1991)', 'Snow White and the Seven Dwarfs (1937)', 'Godfather, The (1972)', 'Wizard of Oz, The (1939)', 'Citizen Kane (1941)', 'Right Stuff, The (1983)']\n",
      "0.9\n",
      "==================================================\n",
      "['Twelve Monkeys (1995)', 'Usual Suspects, The (1995)', 'Star Wars (1977)', 'Pulp Fiction (1994)', 'Shawshank Redemption, The (1994)', 'Forrest Gump (1994)', 'Four Weddings and a Funeral (1994)', 'Silence of the Lambs, The (1991)', 'Fargo (1996)', 'Godfather, The (1972)']\n",
      "0.8\n",
      "==================================================\n",
      "['Toy Story (1995)', 'Mr', 'Birdcage, The (1996)', 'Star Wars (1977)', 'Fargo (1996)', 'Independence Day (ID4) (1996)', 'Return of the Jedi (1983)', 'Jerry Maguire (1996)', \"Devil's Own, The (1997)\", \"My Best Friend's Wedding (1997)\"]\n",
      "0.7\n",
      "==================================================\n",
      "['Toy Story (1995)', 'Usual Suspects, The (1995)', 'Apollo 13 (1995)', 'Pulp Fiction (1994)', 'Shawshank Redemption, The (1994)', 'Forrest Gump (1994)', 'Fugitive, The (1993)', 'Jurassic Park (1993)', 'Fargo (1996)', 'Monty Python and the Holy Grail (1974)']\n",
      "0.9\n",
      "==================================================\n",
      "['Twelve Monkeys (1995)', 'Dead Man Walking (1995)', 'Mighty Aphrodite (1995)', 'Mr', 'Star Wars (1977)', 'Fargo (1996)', 'Truth About Cats & Dogs, The (1996)', 'Rock, The (1996)', 'Swingers (1996)', 'Grosse Pointe Blank (1997)']\n",
      "0.7\n",
      "==================================================\n",
      "[\"Smith Goes to Washington (1939)', 'Sting, The (1973)', 'Graduate, The (1967)']\"]\n",
      "0.0\n",
      "==================================================\n",
      "['']\n",
      "0.0\n",
      "==================================================\n",
      "['Toy Story (1995)', 'Braveheart (1995)', 'Apollo 13 (1995)', 'Star Wars (1977)', 'Forrest Gump (1994)', 'Lion King, The (1994)', 'Aladdin (1992)', 'Silence of the Lambs, The (1991)', 'Independence Day (ID4) (1996)', 'Monty Python and the Holy Grail (1974)']\n",
      "0.7\n",
      "==================================================\n",
      "['Please provide more details about the type of movies you enjoy or any specific genre or theme you are interested in']\n",
      "0.0\n",
      "==================================================\n",
      "['Jurassic Park (1993)', 'Terminator 2: Judgment Day (1991)', 'Independence Day (ID4) (1996)', 'Die Hard (1988)', 'Top Gun (1986)', 'Empire Strikes Back, The (1980)', 'Raiders of the Lost Ark (1981)', 'Return of the Jedi (1983)', 'True Lies (1994)', 'Batman (1989)']\n",
      "0.9\n",
      "==================================================\n",
      "['Toy Story (1995)', 'Blade Runner (1982)', 'Terminator 2: Judgment Day (1991)', 'Silence of the Lambs, The (1991)', 'Die Hard (1988)', 'Monty Python and the Holy Grail (1974)', 'Empire Strikes Back, The (1980)', 'Princess Bride, The (1987)', 'Raiders of the Lost Ark (1981)', 'Return of the Jedi (1983)']\n",
      "0.9\n",
      "==================================================\n",
      "['Mr', 'Braveheart (1995)', 'Star Wars (1977)', 'Pulp Fiction (1994)', 'Shawshank Redemption, The (1994)', 'Forrest Gump (1994)', 'Fargo (1996)', 'Princess Bride, The (1987)', 'Raiders of the Lost Ark (1981)', 'Amadeus (1984)']\n",
      "0.6\n",
      "==================================================\n",
      "['Star Wars (1977)', 'Terminator 2: Judgment Day (1991)', 'Die Hard (1988)', 'Willy Wonka and the Chocolate Factory (1971)', 'Monty Python and the Holy Grail (1974)', 'Raiders of the Lost Ark (1981)', 'Aliens (1986)', 'Apocalypse Now (1979)', 'Return of the Jedi (1983)', 'Terminator, The (1984)']\n",
      "0.6\n",
      "==================================================\n",
      "['Holland\\'s Opus (1995)\", \\'Star Wars (1977)\\', \\'Fargo (1996)\\', \\'Rock, The (1996)\\', \\'Independence Day (ID4) (1996)\\', \\'Return of the Jedi (1983)\\', \\'Star Trek: First Contact (1996)\\', \\'Jerry Maguire (1996)\\', \\'Men in Black (1997)\\']']\n",
      "0.0\n",
      "==================================================\n",
      "['']\n",
      "0.0\n",
      "==================================================\n",
      "[]\n",
      "0\n",
      "==================================================\n",
      "[\"Devil's Own, The (1997)\", 'Contact (1997)', 'Chasing Amy (1997)', 'Full Monty, The (1997)', 'English Patient, The (1996)', 'Scream (1996)', 'Liar Liar (1997)', 'Air Force One (1997)', 'In & Out (1997)', 'Mother (1996)']\n",
      "0.6\n",
      "==================================================\n",
      "['Star Wars (1977)', 'Contact (1997)', 'George of the Jungle (1997)', 'Full Monty, The (1997)', 'English Patient, The (1996)', 'Scream (1996)', 'Evita (1996)', 'Liar Liar (1997)', 'Air Force One (1997)', 'In & Out (1997)']\n",
      "0.7\n",
      "==================================================\n",
      "['']\n",
      "0.0\n",
      "==================================================\n",
      "['Toy Story (1995)', 'Twelve Monkeys (1995)', 'Star Wars (1977)', 'Fargo (1996)', 'Rock, The (1996)', 'Independence Day (ID4) (1996)', 'Willy Wonka and the Chocolate Factory (1971)', 'Return of the Jedi (1983)', 'Jerry Maguire (1996)', 'Men in Black (1997)']\n",
      "0.7\n",
      "==================================================\n",
      "['']\n",
      "0.0\n",
      "==================================================\n",
      "['George of the Jungle (1997)', 'Full Monty, The (1997)', 'English Patient, The (1996)', 'Scream (1996)', 'Evita (1996)', 'Rosewood (1997)', 'Liar Liar (1997)', 'Air Force One (1997)', 'L', 'Rainmaker, The (1997)']\n",
      "0.7\n",
      "==================================================\n",
      "[\"Devil's Own, The (1997)\", 'Contact (1997)', 'George of the Jungle (1997)', 'English Patient, The (1996)', 'Scream (1996)', 'Evita (1996)', 'Liar Liar (1997)', 'Air Force One (1997)', 'L', 'Fly Away Home (1996)']\n",
      "0.3\n",
      "==================================================\n",
      "['A']\n",
      "0.0\n",
      "==================================================\n",
      "['Braveheart (1995)', 'Stargate (1994)', 'Jurassic Park (1993)', 'Terminator 2: Judgment Day (1991)', 'Raiders of the Lost Ark (1981)', 'Aliens (1986)', 'Alien (1979)', 'Terminator, The (1984)', 'Indiana Jones and the Last Crusade (1989)', 'Die Hard 2 (1990)']\n",
      "1.0\n",
      "==================================================\n",
      "['Toy Story (1995)', 'Braveheart (1995)', 'Star Wars (1977)', 'Forrest Gump (1994)', 'Lion King, The (1994)', 'Aladdin (1992)', 'Rock, The (1996)', 'Twister (1996)', 'Independence Day (ID4) (1996)', 'Beauty and the Beast (1991)']\n",
      "0.7\n",
      "==================================================\n",
      "['Good Will Hunting (1997)', 'English Patient, The (1996)', 'Scream (1996)', 'Evita (1996)', 'Air Force One (1997)', 'In & Out (1997)', \"Devil's Advocate, The (1997)\", 'Titanic (1997)', 'Apt Pupil (1998)', 'As Good As It Gets (1997)']\n",
      "0.7\n",
      "==================================================\n",
      "['Contact (1997)', 'Chasing Amy (1997)', 'Full Monty, The (1997)', 'Good Will Hunting (1997)', 'English Patient, The (1996)', 'Scream (1996)', 'In & Out (1997)', \"Ulee's Gold (1997)\", \"Devil's Advocate, The (1997)\", 'Rainmaker, The (1997)']\n",
      "0.7\n",
      "==================================================\n",
      "['']\n",
      "0.0\n",
      "==================================================\n",
      "['Lion King, The (1994)', 'Jurassic Park (1993)', 'Silence of the Lambs, The (1991)', 'Rock, The (1996)', 'Independence Day (ID4) (1996)', 'Monty Python and the Holy Grail (1974)', 'Empire Strikes Back, The (1980)', 'Aliens (1986)', 'Return of the Jedi (1983)', 'Alien (1979)']\n",
      "0.9\n",
      "==================================================\n",
      "['Toy Story (1995)', 'Silence of the Lambs, The (1991)', 'Truth About Cats & Dogs, The (1996)', 'Twister (1996)', 'Independence Day (ID4) (1996)', 'Sound of Music, The (1965)', 'Empire Strikes Back, The (1980)', 'Raiders of the Lost Ark (1981)', 'Return of the Jedi (1983)', 'Dead Poets Society (1989)']\n",
      "1.0\n",
      "==================================================\n",
      "['Willy Wonka and the Chocolate Factory (1971)', 'Monty Python and the Holy Grail (1974)', 'Empire Strikes Back, The (1980)', 'Raiders of the Lost Ark (1981)', 'Aliens (1986)', 'Return of the Jedi (1983)', 'Alien (1979)', 'Amadeus (1984)', 'Back to the Future (1985)', 'Young Frankenstein (1974)']\n",
      "1.0\n",
      "==================================================\n",
      "['Holland\\'s Opus (1995)\", \\'Star Wars (1977)\\', \\'Fargo (1996)\\', \\'Truth About Cats & Dogs, The (1996)\\', \\'Rock, The (1996)\\', \\'Twister (1996)\\', \\'Independence Day (ID4) (1996)\\', \\'Godfather, The (1972)\\', \\'Willy Wonka and the Chocolate Factory (1971)\\']']\n",
      "0.0\n",
      "==================================================\n",
      "[\"Please provide more details about your preferences or the specific movies you've watched, and I'll be happy to assist you further\"]\n",
      "0.0\n",
      "==================================================\n",
      "['A']\n",
      "0.0\n",
      "==================================================\n",
      "['Taxi Driver (1976)', 'Blade Runner (1982)', 'Silence of the Lambs, The (1991)', '2001: A Space Odyssey (1968)', 'Clockwork Orange, A (1971)', 'Alien (1979)', 'Psycho (1960)', 'Terminator, The (1984)', 'Indiana Jones and the Last Crusade (1989)', 'North by Northwest (1959)']\n",
      "0.6\n",
      "==================================================\n",
      "['To provide accurate recommendations, more information about your preferences is needed']\n",
      "0.0\n",
      "==================================================\n",
      "['Postino, Il (1994)', 'Star Wars (1977)', 'Fargo (1996)', 'Lone Star (1996)', 'Bound (1996)', 'Return of the Jedi (1983)', 'Chasing Amy (1997)', 'Heat (1995)', 'Secrets & Lies (1996)', 'Scream (1996)']\n",
      "0.4\n",
      "==================================================\n",
      "['Toy Story (1995)', 'Braveheart (1995)', 'Pulp Fiction (1994)', 'Shawshank Redemption, The (1994)', 'Much Ado About Nothing (1993)', 'Terminator 2: Judgment Day (1991)', 'Wizard of Oz, The (1939)', 'Die Hard (1988)', 'Monty Python and the Holy Grail (1974)', 'Raiders of the Lost Ark (1981)']\n",
      "0.4\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\src\\UF_prompt_engineering.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m n \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m ns \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m recommendations, hit_rate \u001b[39m=\u001b[39m rec_from_openai(df, m, n, ns, user_id, temp_1, temp_2, client)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m hit_rates\u001b[39m.\u001b[39mappend(hit_rate)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(recommendations)\n",
      "\u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\src\\UF_prompt_engineering.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m prediction_1 \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m Input_2 \u001b[39m=\u001b[39m temp_2\u001b[39m.\u001b[39mformat(candidate_movies, selected_watched_movies, selected_watched_movies_genres, prediction_1)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     messages\u001b[39m=\u001b[39;49m [{ \u001b[39m'\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m : Input_2}],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m     \u001b[39m# temperature=0,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39m# max_tokens=512,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     \u001b[39m# top_p=1,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     \u001b[39m# frequency_penalty=0,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     \u001b[39m# presence_penalty=0,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m prediction_2 \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39m# print(Input_1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m# print(prediction_1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# print(Input_2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicho/Documents/GitHub/LLM-Recommender-System/src/UF_prompt_engineering.ipynb#W1sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39m# print(prediction_2)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\openai\\_utils\\_utils.py:301\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 301\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\openai\\resources\\chat\\completions.py:598\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    552\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    553\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    597\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 598\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    599\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    600\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[0;32m    601\u001b[0m             {\n\u001b[0;32m    602\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[0;32m    603\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[0;32m    604\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[0;32m    605\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[0;32m    606\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[0;32m    607\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[0;32m    608\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[0;32m    609\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[0;32m    610\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[0;32m    611\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[0;32m    612\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[0;32m    613\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[0;32m    614\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[0;32m    615\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[0;32m    616\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[0;32m    617\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[0;32m    618\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[0;32m    619\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[0;32m    620\u001b[0m             },\n\u001b[0;32m    621\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[0;32m    622\u001b[0m         ),\n\u001b[0;32m    623\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    624\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[0;32m    627\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    628\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[0;32m    629\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\openai\\_base_client.py:1096\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1082\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1083\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1084\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1091\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1092\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1093\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1094\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1095\u001b[0m     )\n\u001b[1;32m-> 1096\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\openai\\_base_client.py:856\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    848\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    849\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    854\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    855\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 856\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    857\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    858\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    859\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    860\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    861\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    862\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\openai\\_base_client.py:882\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    879\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[0;32m    883\u001b[0m         request,\n\u001b[0;32m    884\u001b[0m         auth\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcustom_auth,\n\u001b[0;32m    885\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[0;32m    886\u001b[0m     )\n\u001b[0;32m    887\u001b[0m     log\u001b[39m.\u001b[39mdebug(\n\u001b[0;32m    888\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mHTTP Request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m, request\u001b[39m.\u001b[39mmethod, request\u001b[39m.\u001b[39murl, response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mreason_phrase\n\u001b[0;32m    889\u001b[0m     )\n\u001b[0;32m    890\u001b[0m     response\u001b[39m.\u001b[39mraise_for_status()\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpx\\_client.py:901\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    893\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[0;32m    894\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[0;32m    895\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    896\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[0;32m    897\u001b[0m )\n\u001b[0;32m    899\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 901\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[0;32m    902\u001b[0m     request,\n\u001b[0;32m    903\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[0;32m    904\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[0;32m    905\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[0;32m    906\u001b[0m )\n\u001b[0;32m    907\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpx\\_client.py:929\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    926\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[0;32m    928\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 929\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[0;32m    930\u001b[0m         request,\n\u001b[0;32m    931\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[0;32m    932\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[0;32m    933\u001b[0m     )\n\u001b[0;32m    934\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpx\\_client.py:966\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    964\u001b[0m     hook(request)\n\u001b[1;32m--> 966\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    968\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpx\\_client.py:1002\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    998\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    999\u001b[0m     )\n\u001b[0;32m   1001\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[1;32m-> 1002\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[0;32m   1004\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1006\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpx\\_transports\\default.py:228\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    215\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[0;32m    216\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[0;32m    217\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[0;32m    226\u001b[0m )\n\u001b[0;32m    227\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 228\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[0;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[0;32m    233\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[0;32m    234\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[0;32m    235\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[0;32m    236\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[0;32m    237\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[39mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    267\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_closed(status)\n\u001b[1;32m--> 268\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m    269\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[0;32m    252\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    253\u001b[0m     \u001b[39m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[39m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[39m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[39m# up as HTTP/1.1.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool_lock:\n\u001b[0;32m    261\u001b[0m         \u001b[39m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[0;32m    262\u001b[0m         \u001b[39m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m    101\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpcore\\_sync\\http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[0;32m    132\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[1;32m--> 133\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpcore\\_sync\\http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[0;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    105\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[0;32m    106\u001b[0m     (\n\u001b[0;32m    107\u001b[0m         http_version,\n\u001b[0;32m    108\u001b[0m         status,\n\u001b[0;32m    109\u001b[0m         reason_phrase,\n\u001b[0;32m    110\u001b[0m         headers,\n\u001b[1;32m--> 111\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_receive_response_headers(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    112\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[0;32m    113\u001b[0m         http_version,\n\u001b[0;32m    114\u001b[0m         status,\n\u001b[0;32m    115\u001b[0m         reason_phrase,\n\u001b[0;32m    116\u001b[0m         headers,\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[0;32m    120\u001b[0m     status\u001b[39m=\u001b[39mstatus,\n\u001b[0;32m    121\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     },\n\u001b[0;32m    128\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpcore\\_sync\\http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    173\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[0;32m    178\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpcore\\_sync\\http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[0;32m    211\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 212\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[0;32m    213\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    214\u001b[0m     )\n\u001b[0;32m    216\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\nicho\\Documents\\GitHub\\LLM-Recommender-System\\.openai_env\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1256\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1257\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1258\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[0;32m   1260\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[0;32m   1133\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[0;32m   1134\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "df = pd.read_csv('../data/processed_movie100k.csv')\n",
    "\n",
    "temp_1 = \"\"\"\n",
    "Candidate Set (candidate movies): {}.\n",
    "The movies I have watched (watched movies): {}.\n",
    "Their genres are: {}.\n",
    "Step 1: What features are most important to me when selecting movies (Summarize my preferences briefly)? \n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "temp_2 = \"\"\"\n",
    "Candidate Set (candidate movies): {}.\n",
    "The movies I have watched (watched movies): {}.\n",
    "Their genres are: {}.\n",
    "Step 1: What features are most important to me when selecting movies (Summarize my preferences briefly)? \n",
    "Answer: {}.\n",
    "Step 2: Can you recommend 10 movies from the Candidate Set similar to but not in the selected movies I've watched?.\n",
    "(Format: Here are the 10 movies recommended for you: [no. a candidate movie])\n",
    "Answer: \n",
    "\"\"\"\n",
    "hit_rates = []\n",
    "for i in range(1, 101):\n",
    "    user_id = i\n",
    "    m = 10\n",
    "    n = 5\n",
    "    ns = 20\n",
    "    recommendations, hit_rate = rec_from_openai(df, m, n, ns, user_id, temp_1, temp_2, client)\n",
    "    hit_rates.append(hit_rate)\n",
    "    print(recommendations)\n",
    "    print(hit_rate)\n",
    "    print('='*50)\n",
    "print(f'Average hit rate: {np.mean(hit_rates)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
